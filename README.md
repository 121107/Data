## Course 8600 Data to Decision
### Advisor Dr. Andrea Grover

### About Myself  

I am [Abu  Bakar Siddiqur Rahman](https://www.linkedin.com/in/abu-bakar-siddiqur-rahman-rocky-8a6787119/), a first year (ongoing second semester) PhD student at the University of Nebraska at Omaha. I have completed Masters in Computer Science from Centro de Investigacion en Computacion, Instituto Politecnico Nacional on 2021. In previous, I was in Rajshahi University of Engineering and Technology to complete my undergraduate degree from the dept. of Electrical and Electronic Engineering on 2018. My research interest is on Machine Learning Applications. I would love to travel and see the green nature. Besides that, I also would like to writing poems, cooking, practicing taekwondo.


### Course Learning

**_There are two Individual Assignment part for the Course. These are:_**
## 1. [Data Entry Analysis](https://github.com/121107/Data/blob/master/Data%20Entry%20Analysis)

**Data cleaning and documentation**

**(i) Literature review:** (Oct 7 to Oct 9)

   * What is data cleaning and documentation?  

   * What decision should be considered to data cleaning task?

   * To watch YouTube videos or gather knowledge from other sources about R to accomplish data cleaning



**(ii) Observing data:** (Oct 10 Oct 13)

    * Where does the data come from (data source)? How much information does it provide us with about a particular task based on the data? The information of different existing variables in data to predict the dependent variables (target variable)?  

    * How many rows and columns have the data sets for each data source? (Must include each row and column name to better understanding)

    * To find whether there are any intellectual policy constraints in the data or not. Is there enough information about licensing of the data (if not, what is missing)?

**_Note 1: writing limitation for Observing data is 1-2 paragraph_**



**(iii) Make Decisions:** (Oct 14 to Oct 17)

**A. Metadata**

  * To find relevant information to interpret and understand the data  

  * To find missing information from data (if needed). Missing information means missing values, unstandardized content, entity matching, integration, etc.  

**_Note 2: writing limitation for metadata is 1-2 paragraph_**

**B. Remediate Data**

To describe the logic if any information (variables) needs to add in the data that seems a key factor in our appearance to make any productive decision after observing the data  

**_Note 3: writing limitation for remediate data is 1 paragraph_**



**(iv) R code** (oct 18 to Oct 22)

To do the R code for the data cleaning (parsing, eliminate unnecessary strings: regex, find common words etc.)



**(v) Writing Documentation and update the README.md in GitHub** (Oct 23 to Oct 28)

    * An R script and a text description will have to be attached to the writing documentation. The text description is nothing but the code description of R.

    * A contribution statement will have to be added to this section

    * Finally, update the README.md in the GitHub  

## 2. [Data Exploration](https://github.com/121107/Data/blob/master/Data%20Exploration)
   * This will appear soon

![A cat image](https://placekitten.com/200/300)

## License
The [license](https://github.com/121107/Data/blob/master/License) can be found here.
